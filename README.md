# audaio
A practical compilation of libraries, case studies, resources, datasets, and research papers revolving around deep learning/machine learning for audio. ðŸŽ¶ðŸŽ¶ðŸŽ¶
Reasonable resources you will actually use!

## Audio ML Landscape Map
- I will add this very soon!

## Datasets
- [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)
- [NSynth Dataset](https://magenta.tensorflow.org/datasets/nsynth)
- [Freesound Loop Dataset](https://zenodo.org/record/3967852#.YvPm7i8w2tW)


## Libraries
### End-to-end Toolkits
- [DeepSpeech](https://github.com/mozilla/DeepSpeech): an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.
- [PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech): Easy-to-use Speech Toolkit including SOTA/Streaming ASR with punctuation, influential TTS with text frontend, Speaker Verification System, End-to-End Speech Translation and Keyword Spotting.
- [NeMo](https://github.com/NVIDIA/NeMo): a toolkit for conversaional AI
- [Speech Brain](https://github.com/speechbrain/speechbrain): an open-source and all-in-one conversational AI toolkit based on PyTorch.
### Data Transformation and Manipulation
- [torchaudio](https://github.com/pytorch/audio): Data manipulation and transformation for audio signal processing, powered by PyTorch
- [nlpaug](https://github.com/makcedward/nlpaug): Data augmentation for NLP. This has spectrogram and audio input support. Check [this](https://github.com/makcedward/nlpaug/blob/master/example/spectrogram_augmenter.ipynb) and [this](https://github.com/makcedward/nlpaug/blob/master/example/audio_augmenter.ipynb)
- [pedalboard](https://github.com/spotify/pedalboard): Spotify's Python library for working with audio. Internally, SPotify uses this for data augmentation and improving machine learning models.
- [Deezer](https://github.com/deezer/spleeter): Deezer source separation library including pretrained models.
- [Basic Pitch](https://github.com/spotify/basic-pitch): A lightweight yet powerful audio-to-MIDI converter with pitch bend detection
- [librosa](https://github.com/librosa/librosa): Python library for audio and music analysis

## Comparisons
- Best library for certain tasks? Where to focus and when learning tools?

## Getting Started
- How to use librosa, one end-to-end tooklkit, torchaudio
- Fundamental papers related to audio deep learning
- Guided walkthroughs from data preparation to deployment


## Audio Generation
### Learning Resource
### Research Papers
## Music Source Separation
## Genre Recognition
## Automatic Speech Recognition
### Learning Resource
- [Essential Guide to ASR](https://developer.nvidia.com/blog/essential-guide-to-automatic-speech-recognition-technology/)
- [The Future of Speech Recognition](https://thegradient.pub/the-future-of-speech-recognition/)
### Research Papers
- [Citrinet](https://arxiv.org/abs/2104.01721)
## Music Information Retrieval
## Music Recommendation
## Podcast Summarization
## Other Research Papers
- [Vocal Effort Modeling](https://machinelearning.apple.com/research/vocal-effort-modeling)
- [Improving Voice Trigger Detection](https://machinelearning.apple.com/research/improving-voice-trigger)

| Syntax      | Description | Test Text     |
| :---        |    :----:   |          ---: |
| Header      | Title       | Here's this   |
| Paragraph   | Text        | And more      |
